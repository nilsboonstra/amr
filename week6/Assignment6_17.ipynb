{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "### GROUP NUMBER : 17\n",
    "### STUDENT NAMES :  Henk, Lodewijk, Nils\n",
    "### STUDENT NUMBERS : 11676892, 11054115, 11784415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This exercise extends and builds on the results of Assignment 5. With landmark‐based localizalization from Assignment 5 relying on an a priori known map, this assignment focuses on autonomous map building, while exploring the environment. This is described in detail in in chapter 5.8 [p. 348-356]. \n",
    "\n",
    "In the scope of this assignment we will use the same robot described in Assignment 5, which can be described by its $x$ and $y$ coordinates and the orientation $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of a figure\n",
    "f, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "ax.set_xlim(-2,2)\n",
    "ax.set_ylim(-2,2)\n",
    "\n",
    "# Initial state [x,y,theta]\n",
    "x_0 = [0,0,0]\n",
    "# Distance between the wheels\n",
    "b = 1\n",
    "\n",
    "# Plotting function to visualize the robot\n",
    "draw_robot(x=x_0, b=b, label='${\\\\bf x}_{t}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFK SLAM\n",
    "Review Kalman Filter Localiza on and Line Parametriza on from the previous assignment. The idea behind EKF SLAM is to treat the map in a probabilistic way, similar to treating the pose of the robot. Therefore, we add the parameters $\\alpha^i$ and $\\rho^i$ of each landmark $m_i$ to the EKF state:\n",
    "\\begin{equation}\n",
    "{\\bf x}_t =\\left[x, y, \\theta, \\alpha^1, \\rho^1, \\dots, \\alpha^K, \\rho^K \\right]^T\n",
    "\\end{equation}\n",
    "We assume that the landmarks do not have any dynamics, i.e. they are static in the world frame.\n",
    "By properly including the landmarks in the state vector, we can now obtain the uncertainty of the landmarks as well as the correlations between them.\n",
    "For the implementation of the SLAM‐filter, we assume that we know the number of landmarks and have a (very rough) estimate of them at startup. This simplifies the implementational details significantly, as no landmark book‐keeping is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time $t-1$ the robot has access to a rough estimate of the map $M$. Each landmark ${\\bf m}^i$ is associated with a mean vector $\\hat{\\bf m}^i=[\\hat{\\alpha}^i,\\hat{\\rho}^i]$ and a $2\\times2$ covariance matrix ${ \\hat{\\bf P}_{m^i}}$ which expresses the corresponding uncertainty. The ground truth map (on the left) is compared with the initial robot belief (on the right) in the figure below.\n",
    "Note that the expected landmarks according to the robot belief ${\\bf m}^i$ are represented with solid lines, while the other semi-transparent lines in the picture are samples from the distribution $\\mathcal{N}(\\hat{\\bf m}^i, \\hat{\\bf P}_{m^i})$, which represent the robot uncertainty on the landmark positions (the more sparse the samples, the less certain the robot about the map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "ax[0].set_title('True Map')\n",
    "ax[1].set_title('Initial Map estimate')\n",
    "\n",
    "ax[0].set_xlim(-4,4)\n",
    "ax[0].set_ylim(-4,4)\n",
    "\n",
    "# True map (unknown to the robot)\n",
    "true_M = get_default_map()\n",
    "\n",
    "# Obtain a initial rough estimate of the map\n",
    "M, P_M = get_sampled_map()\n",
    "\n",
    "# Draw the true map on the left\n",
    "draw_map(true_M, ax=ax[0], color='red')\n",
    "\n",
    "# Draw the initial robot estimate on the right\n",
    "draw_map_estimate(M, P_M, ax=ax[1], color='red')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the scope of this assignment, we will consider an initial estimate with low uncertaity for the first two landmarks ${\\bf m}^1$ and ${\\bf m}^2$ (two bottom lines in the figure above) and high uncertainty for the rest of the map.\n",
    "\n",
    "Each landmark in the map can be alternatively represented as a point in polar coordinate space, while the robot initial map estimate can be visualized by the level sets the Gaussian distribution $\\mathcal{N}(\\hat{\\bf m}^i, \\hat{\\bf P}_{m^i})$, which correspond to the initial map knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "f, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "ax.set_xlim(-1,2.5)\n",
    "ax.set_ylim(-4,4)\n",
    "\n",
    "# True map (unknown to the robot)\n",
    "true_M = get_default_map()\n",
    "\n",
    "# Obtain a initial rough estimate of the map (robot initial knowledge)\n",
    "M, P_M = get_sampled_map()\n",
    "\n",
    "draw_landmarks_distribution(M,P_M)\n",
    "draw_landmarks(true_M, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Prediction\n",
    "Assignment 5 dealt with the state propagation model of the robot when not including the landmarks in the state. As these landmarks are now part of the state vector, we have to adjust the state propagation model. Since the landmarks are considered to be static, we model them using zero velocity dynamics.\n",
    "\\begin{equation}\n",
    "    \\Delta\\alpha^i = 0\\\\\n",
    "    \\Delta\\rho^i = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 Points)\n",
    "Derive and implement the state prediction and covariance propagation for the state defined above, To this end, you can adapt the state transition function defined below or use your implementation from Assignment 5. The $\\textit{state_transition}$ function maps the\n",
    "state ${\\bf x}_{t-1}$ at time $t−1$ to the state ${\\bf x}_t$ given the wheel odometry ${\\bf u}_t=[\\Delta s_l, \\Delta s_r]$ as defined in the previous assignment.\n",
    "\\begin{equation}\n",
    "\\hat{\\bf x}_t = f({\\bf x}_{t-1}, {\\bf u}_t)\n",
    "\\end{equation}\n",
    "\n",
    "Additionally, derive ${\\bf F}_x$ and ${\\bf F}_u$ for this formulation and implement your results in the function below.\n",
    "\\begin{equation}\n",
    "{\\bf F}_x = \\frac{\\partial f({\\bf x}_{t-1}, {\\bf u}_t)}{\\partial {\\bf x}} \\ \\ \\ \\ \\ \\ \\ \\  {\\bf F}_u = \\frac{\\partial f({\\bf x}_{t-1}, {\\bf u}_t)}{\\partial {\\bf u}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function implements the transition function as defined \n",
    "# in Assignment 5, you can either start from this implementation\n",
    "# or use your own\n",
    "\n",
    "def transition_function(x, u, b): \n",
    "    '''\n",
    "    Inputs:\n",
    "        x: previous state at t-1\n",
    "        u: control inputs\n",
    "        b: wheel distance\n",
    "    Return:\n",
    "        x_next: estimate of the current state\n",
    "        F_x: Jacobian of the transition function with respect to the state\n",
    "        F_u: Jacobian of the transition function with respect to the control input\n",
    "    '''\n",
    "    \n",
    "    ####################\n",
    "    # UPDATE FROM HERE #\n",
    "    ####################\n",
    "    \n",
    "    # Convert x and u to numpy arrays\n",
    "    x = np.array(x)\n",
    "    u = np.array(u)\n",
    "    \n",
    "    x_t = np.array([((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b)),\n",
    "                ((u[1] - u[0]) / b),\n",
    "                   ((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b)),\n",
    "                   ((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b)),\n",
    "                   ((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b)),\n",
    "                   ((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b)),\n",
    "                   ((u[0] + u[1]) / 2) * np.cos(x[2] + ((u[1] - u[0]) / 2 * b)), \n",
    "                ((u[0] + u[1]) / 2) * np.sin(x[2] + ((u[1] - u[0]) / 2 * b))])\n",
    "    \n",
    "    # Compute delta_s and delta_theta to use for the computation of F_x and F_u\n",
    "    delta_s = u.mean()\n",
    "    delta_theta = (u[1] - u[0]) / b\n",
    "    \n",
    "    # Compute the state update delta_x\n",
    "    delta_x = np.array([\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "        delta_theta,\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "        delta_s * np.cos(x[2] + delta_theta / 2),\n",
    "        delta_s * np.sin(x[2] + delta_theta / 2),\n",
    "    ])\n",
    "    \n",
    "    # The next state is obtained by summing the previous one with the variation delta_x\n",
    "    x_next = x + delta_x\n",
    "    \n",
    "    # Definition of F_x\n",
    "    F_x = np.eye(13)\n",
    "    F_x[0,2] = -delta_s * np.sin(x[2] + delta_theta / 2)\n",
    "    F_x[1,2] =  delta_s * np.cos(x[2] + delta_theta / 2)\n",
    "\n",
    "    \n",
    "    # Definition of F_u\n",
    "    F_u =np.array([\n",
    "        [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            1/b,\n",
    "            -1/b\n",
    "        ],\n",
    "                [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "                [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "                [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "                [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "                [\n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0), \n",
    "            0.5 * np.cos(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.sin(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "        [\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) - delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0),\n",
    "            0.5 * np.sin(x[2] + delta_theta / 2.0) + delta_s / (2 * b) * np.cos(x[2] + delta_theta / 2.0)\n",
    "        ],\n",
    "    ])\n",
    "    \n",
    "    ###########\n",
    "    # TO HERE #\n",
    "    ###########\n",
    "    \n",
    "    # Do not remove the following assertions and make sure your x_next, F_u and F_x shapes are correct\n",
    "    assert x_next.shape == x.shape\n",
    "    assert F_x.shape[1] == x.shape[0] and F_x.shape[0] == x.shape[0]\n",
    "    assert F_u.shape[0] == x.shape[0] and F_u.shape[1] == u.shape[0]\n",
    "    \n",
    "    return x_next, F_x, F_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously to the previous assignment, we start by checking the distribution for the next state defined by $\\hat{\\bf x}_t$ and $\\hat{\\bf P}_t$ (level sets of the Gaussian distribution) coincides with the positions of the robot after performing the noisy movement specified by ${\\bf u}_t$ (red dots).\n",
    "Note that the state vector has dimensionality $3 + 2 \\cdot 5 = 13$ and the corresponding covariance is a $[13\\times13]$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the following 2 cells do not run until you update the update_measurement function\n",
    "# and your x_next, F_x and F_u have the correct shapes\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# Set up for the matplotlib figure\n",
    "f, ax = plt.subplots(1,1, figsize=(5,5), sharex=True, sharey=True)\n",
    "ax.set_title('Next State position distribution')\n",
    "ax.set_xlim(-1,3)\n",
    "ax.set_ylim(-1,3)\n",
    "\n",
    "# Distance between the wheels\n",
    "b = 1\n",
    "\n",
    "# Robot state [x, y, theta] at time t-1\n",
    "x = [0,0,1]\n",
    "\n",
    "# Covariance matrix  for state at t-1\n",
    "P = np.eye(len(x)) * 0.1\n",
    "\n",
    "# Draw the robot\n",
    "draw_robot(x, b, label='${\\\\bf x}_{t-1}$')\n",
    "\n",
    "# Get an initial rough estimation landmarks in polar coordinates and\n",
    "# their respective covariance\n",
    "M, P_M = get_sampled_map()\n",
    "\n",
    "# Add the map to the current state\n",
    "# Note that x has now size [13] while P is a [13 x 13] matrix\n",
    "x = np.concatenate([x] + M, 0)\n",
    "P = block_diag(*([P] + P_M))\n",
    "\n",
    "\n",
    "# Amount of desired displacement for the two wheels [left_wheel, right_wheel]\n",
    "# You can change this two values to test your function\n",
    "u = [2., 2]\n",
    "\n",
    "# Amount of noise for the robot movement\n",
    "k = 0.05\n",
    "\n",
    "# Perform N=100 experiments by initializing the robot at state x and performing the noisy movement\n",
    "draw_simulation(x[:3], P[:3,:3], u, k, b, N=100)\n",
    "\n",
    "# Use transition_function to determine the estimated next state and the Jacobians F_x and F_u\n",
    "x_next, F_x, F_u = transition_function(x, u, b)\n",
    "\n",
    "# Determine the covariance matrix for the nosy movement Q following Equation (2) Assignment 5\n",
    "Q = compute_Q(u, k)\n",
    "\n",
    "# The covariance at time t is obtained using Equation (3) Assignment 5\n",
    "P_next = F_x @ P @ F_x.T + F_u @ Q @ F_u.T\n",
    "\n",
    "# Draw the distribution corresponding to the next state\n",
    "draw_state_distribution(x_next, P_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we visualize how the landmarks in the robot state are updated by plotting their distribution in polar coordinates for both ${\\bf x}_{t-1}$ and ${\\bf x}_t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "ax[0].set_title('Landmarks distribution for ${\\\\bf x}_{t-1}$')\n",
    "ax[1].set_title('Landmarks distribution for ${\\\\bf x}_{t}$')\n",
    "ax[0].set_xlim(-1,3)\n",
    "ax[0].set_ylim(-4,4)\n",
    "\n",
    "# Draw the landmarks distribution before the update on the left\n",
    "draw_landmarks_distribution(x[3:],P[3:, 3:], ax=ax[0])\n",
    "\n",
    "# Draw the landmarks distribution after the update on the right\n",
    "draw_landmarks_distribution(x_next[3:],P_next[3:, 3:], ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Hint:}$\n",
    "1. Should the predictive distribution for $x$, $y$ and $\\theta$ differ from the EFK implementation used for Assignemnt 5?\n",
    "2. Does the robot change its uncertainty regarding the landmarks just by performing some movement? Should the landmarks distribution change for the new state ${\\bf x}_t$?\n",
    "\n",
    "Try to answer answer this question and reason about your results before proceeding to $\\textbf{Task 4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement function\n",
    "\n",
    "The main work of EKF SLAM is done in the measurement update. We assume that all landmarks are visible, and that the number of landmarks does not change. This is not a limitation, but it simplifies implementation and debugging effort at this stage. Measurement association and update work similarly to Exercise 4, except that the measurement Jacobians ${\\bf H}^i$ need special attention. We can show that the relative position and heading of the robot with respect to the landmarks can be estimated. However, the global position and heading of the robot as well as the landmarks is not observable. This can be intuitively explained by the fact that if both robot and landmarks are moved or rotated by the same amount simultaneously,\n",
    "we cannot detect this motion using only relative distance or bearing measurements of the robot with respect to the walls or wheel encoder information. To eliminate these degrees of freedom, we fix the first two landmarks in the state vector (assuming that both walls are not parallel), in order to fully constrain the unobservable states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (4 Points)\n",
    "Based on the implementation in Assignment 5, implement a measurement function that returns the predicted measurement given the state vector (which is now including both robot state and landmarks) and the landmark index as defined in the following equation. To this end, update $\\textit{measurement_function}$ (Hint: What has actually changed since the previous exercise?).\n",
    "\\begin{equation}\n",
    "    \\hat{\\bf z}^i_t = h^i(\\hat{\\bf x}_t)\n",
    "\\end{equation}\n",
    "Additionally, provide the corresponding Jacobian of the measurement with respect to the state vector $\\hat{\\bf H}_x$. Compared to Assignment 5, the landmark position is now part of the state vector. This has to be reflected in the computation of the Jacobian.\n",
    "\\begin{equation}\n",
    "    \\hat{\\bf H}_x^i = \\frac{\\partial h^i(\\hat{\\bf x}_t)}{\\partial {\\bf x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_function(x, i):\n",
    "    '''\n",
    "    Inputs:\n",
    "        x: estimate of the state at time t\n",
    "        i: landmark id\n",
    "    Return:\n",
    "        z: measurement as perceived by a robot with state x\n",
    "        H: Jacobian of the measurement model with respect to the state\n",
    "    '''\n",
    "    \n",
    "    ####################\n",
    "    # UPDATE FROM HERE #\n",
    "    ####################\n",
    "    \n",
    "    # NOTE: The old implementation received a landmark m as an input\n",
    "    # while in this case the input 'i' is a landmark id within the state x\n",
    "    # What is the new m?\n",
    "    \n",
    "    # Convert x to a numpy array\n",
    "    x = np.array(x)\n",
    "   \n",
    "    # Compute the expected measurement z \n",
    "    z = [\n",
    "        m[0]-x[2], \n",
    "        m[1]-(x[0]*np.cos(m[0])+x[1]*np.sin(m[0]))\n",
    "    ]\n",
    "    \n",
    "    # And the measurement Jacobian H\n",
    "    H = [\n",
    "        [0, 0, -1],\n",
    "        [-np.cos(m[0]), -np.sin(m[0]), 0]\n",
    "    ]\n",
    "    \n",
    "    # Convert them to numpy arrays\n",
    "    z = np.array(z)\n",
    "    H = np.array(H)\n",
    "    \n",
    "    ###########\n",
    "    # TO HERE #\n",
    "    ###########\n",
    "    \n",
    "    return z, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the result of your implementation analogously to the previous assignment by first showing the robot landmarks estimate $\\hat{\\bf m}^i_t$ (red lines on the left picture), then comparing the output of the measurement function $\\hat{\\bf z}_t^i$ (red lines on the right picture) with the actual sensor readings ${\\bf z}^j_t$ (dashed blue lines on the right) at time $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this cell does not run until you update the measurement_function function\n",
    "# and your z and H have the correct shapes\n",
    "\n",
    "# Figure Setup\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax[0].set_title(\"World Coordinates\")\n",
    "ax[0].set_xlim(-4,4)\n",
    "ax[0].set_ylim(-4,4)\n",
    "\n",
    "ax[1].set_title(\"Body Coordinates\")\n",
    "ax[1].set_xlim(-4,4)\n",
    "ax[1].set_ylim(-4,4)\n",
    "\n",
    "# Distance between the wheels\n",
    "b = 1\n",
    "\n",
    "# Robot state [x, y, theta] at time t-1\n",
    "x = [0,0,1]\n",
    "\n",
    "# Covariance matrix  for state at t-1\n",
    "P = np.eye(len(x)) * 0.1\n",
    "\n",
    "# Draw the robot on the two subplots\n",
    "draw_robot(x, b, label='${\\\\bf x}_t$', ax=ax[0]) # World coordinates\n",
    "draw_robot([0,0,0], b, label='${\\\\bf x}_t$', ax=ax[1]) # Body frame coordinates\n",
    "\n",
    "# Get an initial rough estimation landmarks in polar coordinates and\n",
    "# their respective covariance\n",
    "M, P_M = get_sampled_map()\n",
    "\n",
    "# True map (unknown to the robot)\n",
    "true_M = get_default_map()\n",
    "\n",
    "# Add the map to the current state\n",
    "x = np.concatenate([x] + M, 0)\n",
    "P = block_diag(*([P] + P_M))\n",
    "\n",
    "# Draw the map in world coordinates on the first picture\n",
    "draw_map(M, ax=ax[0])\n",
    "\n",
    "# Initialize an empty map in robot body coordinate frame\n",
    "robot_M = [] \n",
    "\n",
    "# Use the measurement_function to convert the global coordinates m into local ones z\n",
    "for i in range(len(M)):\n",
    "    z, H = measurement_function(x, i)\n",
    "    robot_M.append(z)\n",
    "\n",
    "\n",
    "# Draw the map in body frame coordinates on the second picture\n",
    "draw_map(robot_M, ax=ax[1])\n",
    "\n",
    "# Take some measurements Z using the robot sensors\n",
    "Z, R = make_measurements(x, true_M)\n",
    "\n",
    "# Draw the robot measurements on the second picture\n",
    "draw_map(Z,  color='blue', dashed=True, ax=ax[1], alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Hint:}$ \n",
    "Make sure that the estimated landmarks $\\hat{\\bf m}^i_t$ are correctly converted from world to body frame coordinates. Note that, in contrast to Assignment 5, the robot measurements ${\\bf z}^j_t$ (in blue on the right) do not necessarily overlap with the robot estimated measurements $\\hat{\\bf z}^i_t$ (in red on the right) since the robot has only approximate knowledge about the map.\n",
    "\n",
    "Make sure your implementation is correct before progressing to the $\\textbf{Task 3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement association\n",
    "Analogously to the previous assignment, the predicted measurements $\\hat{\\bf z}^i_t$ need to be associated to the actual measurements ${\\bf z}^j_t$. This is done by first computing a distance metric $d_t^{ij}$, then associating each measurement to the closest predicted measurement whenever their distance falls in the interval defined by the validation gate $g$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (1 point)\n",
    "Adapt the implementation of the $\\textit{associate_measurements}$ function from the previous exercise considering that the estimated landmark $\\hat{\\bf m}^i_t$ are now part of the state vector $\\hat{\\bf x}_t$.\n",
    "The output and behaviour of this function should be unchanged when compared to the previous assignment.\n",
    "Once again you can either adapt the implementation below or use your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_measurements(x,P,Z,R,g):\n",
    "    '''\n",
    "    Inputs:\n",
    "        x: estimate of the state at time t\n",
    "        P: covariance of the state estimate\n",
    "        Z: list of measurements \n",
    "        R: list of covariance matrices corresponding to the measurements (R[i] is the covariance for Z[i])\n",
    "        g: validation gate\n",
    "    Return:\n",
    "        a: vector of associations between measurements and map entries\n",
    "    '''\n",
    "    ####################\n",
    "    # UPDATE FROM HERE #\n",
    "    ####################\n",
    "    \n",
    "    # NOTE: In contrast with the previous assignment, the map M is not given as an input\n",
    "    # since the landmarks are included in the state x\n",
    "    \n",
    "    # Instantiate an empty distance matrix ds with size [len(Z) x len(M)]\n",
    "    d = np.zeros([len(Z), len(M)])\n",
    "    \n",
    "    # For each measurement id 'i'\n",
    "    for i in range(len(Z)):\n",
    "        \n",
    "        # For each landmark id 'j'\n",
    "        for j in range(len(M)):\n",
    "            \n",
    "            # Consider the i-th measurement\n",
    "            z = Z[i]\n",
    "            R_i = R[i]\n",
    "            \n",
    "            # Consider the j-th landmark\n",
    "            m = M[j]\n",
    "            \n",
    "            # Compute the predicted measurement z_hat and the measurement Jacobian H\n",
    "            # NOTE: Keep in mind that the new implementation of measurement_function uses the\n",
    "            # landmark id instead of the landmark vector 'm'\n",
    "            z_hat, H = measurement_function(x, m)\n",
    "            \n",
    "            # Compute the innoviation vector v\n",
    "            v = z - z_hat\n",
    "            \n",
    "            # Compute the covariance Sigma\n",
    "            Sigma = (H @ P @ H.T) + R_i\n",
    "            \n",
    "            # And use it to determine the distance d_ij\n",
    "            Sigma_inv = np.linalg.inv(Sigma)\n",
    "            d_ij = v.T @ Sigma_inv @ innovation\n",
    "            \n",
    "            # Set the entry in the distance matrix d to its corresponding value\n",
    "            d[i,j] = d_ij\n",
    "    \n",
    "    # Set the distance exceding g^2 to positive infinity\n",
    "    d[d > g**2] = np.inf\n",
    "    \n",
    "    # Identify the minimum for each column\n",
    "    min_values = np.amin(d, 1)\n",
    "    \n",
    "    # The assignment vector is determined by the id of the minumum for each column\n",
    "    a = np.argmin(d, 1)\n",
    "    \n",
    "    # Replace the id of all the assignment that have been distarded by the validation gate to -1 \n",
    "    a[min_values == np.inf] = -1\n",
    "    \n",
    "    ###########\n",
    "    # TO HERE #\n",
    "    ###########\n",
    "\n",
    "    return a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association vector $\\bf a$ obtained by calling your implementation of $\\textit{associate_measurements}$ is shown below. Each measurement is coloured according to the associated landmark and left black if its minumum distance is grater then the threshold specified by the validation gate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this cell does not run correctly until you update measurement_function and associate_measurements\n",
    "\n",
    "# Figure setup\n",
    "f, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "ax.set_title(\"Body Coordinates\")\n",
    "ax.set_xlim(-5,5)\n",
    "ax.set_ylim(-5,5)\n",
    "\n",
    "# Distance between the wheels\n",
    "b = 1\n",
    "\n",
    "# Robot state [x, y, theta] at time t-1\n",
    "x = [0,0,1]\n",
    "\n",
    "# Covariance matrix  for state at t-1\n",
    "P = np.eye(len(x)) * 0.1\n",
    "\n",
    "# Draw the robot on the two subplots\n",
    "draw_robot(x, b, label='${\\\\bf x}_t$') # World coordinates\n",
    "\n",
    "# Get an initial rough estimation landmarks in polar coordinates and\n",
    "# their respective covariance\n",
    "M, P_M = get_sampled_map()\n",
    "\n",
    "# True map (unknown to the robot)\n",
    "true_M = get_default_map()\n",
    "\n",
    "# Add the map to the current state\n",
    "x = np.concatenate([x] + M, 0)\n",
    "P = block_diag(*([P] + P_M))\n",
    "\n",
    "# Validation gate g\n",
    "g = 1\n",
    "\n",
    "# Use the measurement_function to convert the landmarks m into local coordinates z\n",
    "robot_M = [] \n",
    "for i in range(len(M)):\n",
    "    z, _ = measurement_function(x, i)\n",
    "    robot_M.append(z)\n",
    "    \n",
    "    \n",
    "# Take some measurements Z using the robot sensors\n",
    "Z, R = make_measurements(x, true_M)\n",
    "\n",
    "# Determine the association between measurement and map entries\n",
    "a = associate_measurements(x, P, Z, R, g)\n",
    "\n",
    "# Draw each line in the map and its associated measurements with the same color\n",
    "# Note: Make sure your measurement_function is correct first\n",
    "draw_associations(robot_M, Z, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Hint:}$\n",
    "Make sure your implementation is working before progressing to $\\textbf {Task 4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the estimate\n",
    "\n",
    "As a last step to implement the SLAM Extended Kalman Filter procedure, we need to update the robot state according to the measurements. In order to do so we can use the same procedure used for the standard Extended Kalman filter, which now will update both the estimate robot position and the landmarks  in the robot state ${\\bf x}_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 Points)\n",
    "Adapt the a $\\textit{filter_step}$ and $\\textit{compute_innovation}$ functions to read the map directly from the robot state $\\hat{\\bf x}_t$ instead of a map ${\\bf M}$ as given in Assigment 5. You can either adapt the code provided below or write your own implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "\n",
    "def compute_innovation(x, Z_all, R_all, a):\n",
    "    '''\n",
    "    Input:\n",
    "        x: the estimated robot state at time t\n",
    "        Z_all: list of robot measurements at time t\n",
    "        R_all: list of covariance matrices corresponding to the measurements in Z_all\n",
    "        a: measurement-map association vector (as defined in the previous section)\n",
    "    Returns:\n",
    "        v: list of innovation vectors\n",
    "        filtered_H: list of Jacobians H (one for each innovation)\n",
    "        filtered_R: list of Covariance matrices R (one for each innovation)\n",
    "    ''' \n",
    "    \n",
    "    ####################\n",
    "    # UPDATE FROM HERE #\n",
    "    ####################\n",
    "    \n",
    "    # NOTE: The previous implementation received the map M as an input\n",
    "\n",
    "    v = []\n",
    "    filtered_R = []\n",
    "    filtered_H = []\n",
    "    \n",
    "    # For each assignment\n",
    "    for i in range(len(a)):\n",
    "        \n",
    "        # If the value is not -1 (the association has not been filtered by the validation gate)\n",
    "        if a[i] >= 0:\n",
    "            \n",
    "            # Compute the expected measurement (robot body coordinates) and its Jacobian\n",
    "            z_hat, H = measurement_function(x, M[a[i]])\n",
    "            \n",
    "            # Compute the innovation vector\n",
    "            v_i = Z_all[i] - z_hat\n",
    "            \n",
    "            # Add the innovation v_i, the Jacobian H and the covariance R to their respective list \n",
    "            v.append(v_i)\n",
    "            filtered_R.append(R_all[i])\n",
    "            filtered_H.append(H)\n",
    "            \n",
    "    ###########\n",
    "    # TO HERE #\n",
    "    ###########\n",
    "            \n",
    "    return v, filtered_H, filtered_R\n",
    "\n",
    "\n",
    "\n",
    "def filter_step(x, P, u, k, Z, R, g, b):\n",
    "    '''\n",
    "    Input:\n",
    "        x: robot state at time t-1\n",
    "        P: covariance matrix corresponding to the robot state at time t-1\n",
    "        u: control inputs\n",
    "        k: displacement noise factor (see Equation (2))\n",
    "        Z: list of robot measurements at time t\n",
    "        R: list of covariance matrices corresponding to the measurements in Z\n",
    "        g: validation gate\n",
    "        b: distance between the wheels\n",
    "    Returns:\n",
    "        x_next: corrected estimation for the robot state at time t\n",
    "        P_next: corrected covariance corresponding to x_next\n",
    "    '''\n",
    "    \n",
    "    ####################\n",
    "    # UPDATE FROM HERE #\n",
    "    ####################\n",
    "    \n",
    "    # NOTE: The previous implementation received the map M as an input\n",
    "    \n",
    "    # Compute the next x together with the two Jacobians F_x and F_u using the\n",
    "    # previously implemented 'transition_function'\n",
    "    x_next, F_x, F_u = transition_function(x, u, b)\n",
    "    \n",
    "    # Build the covariance matrix following Equation (2)\n",
    "    Q = compute_Q(u, k)\n",
    "    \n",
    "    # Compute the covariance matrix for the next state using Equation (3)\n",
    "    P_next = F_x @ P @ F_x.T + F_u @ Q @ F_u.T\n",
    "    \n",
    "    # Use the 'associate_measurements' to determine which map entries correspond\n",
    "    # to the measurements Z\n",
    "    # Note: The new associate_measurements function does not get the map M \n",
    "    # as an input\n",
    "    a = associate_measurements(x_next, P_next, Z, R, M, g)\n",
    "    \n",
    "    # compute the list of innovations\n",
    "    # NOTE: your updated implementation of compute_innovation does not\n",
    "    # have access the map M\n",
    "    v, H, R = compute_innovation(x_next, Z, R, M, a)\n",
    "    \n",
    "    if len(v) > 0:\n",
    "        # Concatenate the innoviation vectors,\n",
    "        v = np.concatenate(v, 0)\n",
    "        \n",
    "        # the measurement Jacobians\n",
    "        H = np.concatenate(H, 0)\n",
    "        \n",
    "        # and make a block diagonal covariance matrix R\n",
    "        R = block_diag(*R)\n",
    "        \n",
    "        # Compute the covariance Sigma\n",
    "        Sigma = H @ P_next @ H.T + R\n",
    "        \n",
    "        # And use it to compute the Kalman matrix K\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "        K = P_next @ H.T @ Sigma_inv\n",
    "        \n",
    "        # Then use K to compute the correction to the next state distribution\n",
    "        x_next += K @ v\n",
    "        P_next -= K @ Sigma @ K.T \n",
    "        \n",
    "    ###########\n",
    "    # TO HERE #\n",
    "    ###########\n",
    "    \n",
    "    return x_next, P_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check how the robot position is by the Kalman Filter correction by comparing the distribution of the robot position before (on the left) and after (on the right) considering the measurements as in the previous assignment. $\\textit{Hint:}$ Do we expect anything to change with respect to the previous assignment here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this cell does not run correctly until you update the filter_step function\n",
    "\n",
    "# Figure setup\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "ax[0].set_title('Estimated position before measurement')\n",
    "ax[1].set_title('Estimated position after measurement')\n",
    "ax[0].set_xlim(-4,4)\n",
    "ax[0].set_ylim(-4,4)\n",
    "\n",
    "# Distance between the wheels\n",
    "b = 1\n",
    "\n",
    "# Robot state [x, y, theta] at time t-1\n",
    "x = [0,0,1]\n",
    "\n",
    "# Covariance matrix  for state at t-1\n",
    "P = np.eye(len(x)) * 0.1\n",
    "\n",
    "# Get an initial rough estimation landmarks in polar coordinates and\n",
    "# their respective covariance\n",
    "M, P_M = get_sampled_map()\n",
    "true_M = get_default_map()\n",
    "\n",
    "# Add the map to the current state\n",
    "x = np.concatenate([x] + M, 0)\n",
    "P = block_diag(*([P] + P_M))\n",
    "\n",
    "# Draw the robot at time t-1 on both Axis\n",
    "draw_robot(x, b, label='${\\\\bf x}_{t-1}$', alpha=1, ax=ax[0])\n",
    "draw_robot(x, b, label='${\\\\bf x}_{t-1}$', alpha=1, ax=ax[1])\n",
    "\n",
    "# Amount of desired displacement for the two wheels [left_wheel, right_wheel]\n",
    "u = [2, 2]\n",
    "\n",
    "# Amount of noise in the robot movement see Equation (2)\n",
    "k = 0.02\n",
    "\n",
    "# Validation gate\n",
    "g = 1\n",
    "\n",
    "# Draw the map on the two figures\n",
    "draw_map(true_M, ax=ax[0])\n",
    "draw_map(true_M, ax=ax[1])\n",
    "\n",
    "# The actual initial robot position is sampled from the distribution at time t\n",
    "x_actual = np.random.multivariate_normal(mean=x[:3], cov=P[:3,:3])\n",
    "\n",
    "# The position of the robot at the next timestamp is determined by executing the displacement determined by u\n",
    "x_next = execute_instruction(x=x[:3], u=u, b=b, k=k)\n",
    "\n",
    "# Draw the robot at its actual position (noisy) at time t \n",
    "draw_robot(x_next, ax=ax[0], label='${\\\\bf x}_{t}$', b=1, alpha=0.5)\n",
    "draw_robot(x_next, ax=ax[1], label='${\\\\bf x}_{t}$', b=1, alpha=0.5)\n",
    "\n",
    "# Determine the expected new position according to the transition function\n",
    "x_next_est, F_x, F_u = transition_function(x, u, b)\n",
    "\n",
    "# And compute its covariance matrix following Equation (2) and Equation (3)\n",
    "Q = compute_Q(u, k)\n",
    "P_next_est = F_x @ P @ F_x.T + F_u @ Q @ F_u.T\n",
    "\n",
    "# Draw the distribution for the state at time t on the figure on the left\n",
    "draw_state_distribution(x_next_est, P_next_est, ax=ax[0])\n",
    "\n",
    "# Make some measurements in the current position\n",
    "Z, R =  make_measurements(x_next, true_M)\n",
    "\n",
    "# Use the implementation of Kalman filter to determine how to update x_next and P_next\n",
    "x_next_kalman, P_next_kalman = filter_step(x, P, u, k, Z, R, g, b)\n",
    "\n",
    "# Draw the distribution for the robot position after adjusting the estimates using the sensor input\n",
    "draw_state_distribution(x_next_kalman, P_next_kalman, ax=ax[1])\n",
    "\n",
    "#draw_map_estimate(x[3:], P[3:,3:], ax=ax[0], color='blue')\n",
    "#draw_map_estimate(x_next_kalman[3:], P_next_kalman[3:,3:], ax=ax[1], color='blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we visualize how the landmark position is updated after performing the measurement. We can do so by comparing the estimated landmarks (in blue) before $\\hat{\\bf m}^i_{t-1}$ (on the left) and after $\\hat{\\bf m}^i_{t}$ the update (on the right). The ground truth map is shown with red solid lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "ax[0].set_title('Estimated map before measurement')\n",
    "ax[1].set_title('Estimated map after measurement')\n",
    "ax[0].set_xlim(-4,4)\n",
    "ax[0].set_ylim(-4,4)\n",
    "\n",
    "# Draw the map on the two figures\n",
    "draw_map(true_M, ax=ax[0])\n",
    "draw_map(true_M, ax=ax[1])\n",
    "\n",
    "# Draw the landmark estimate before the update on the left\n",
    "draw_map_estimate(x[3:], P[3:,3:], ax=ax[0], color='blue', alpha=0.2)\n",
    "# Draw the landmark estimate after the update on the right\n",
    "draw_map_estimate(x_next_kalman[3:], P_next_kalman[3:,3:], ax=ax[1], color='blue', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same comparison can be performed directly in polar coordinates, in which the landmark estimates are represented as Gaussian distributions, while red dots are used to visualize the ground truth representation of the landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Setup\n",
    "f, ax = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,5))\n",
    "ax[0].set_title('Estimated map before measurement')\n",
    "ax[1].set_title('Estimated map after measurement')\n",
    "ax[0].set_xlim(-1,3)\n",
    "ax[0].set_ylim(-4,4)\n",
    "        \n",
    "# Draw the ground truth landmarks as points in polar coordinates on the two pictures\n",
    "draw_landmarks(true_M, ax=ax[0])\n",
    "draw_landmarks(true_M, ax=ax[1])\n",
    "\n",
    "# Draw the landmark distribution before the update on the left\n",
    "draw_landmarks_distribution(x[3:],P[3:, 3:], ax=ax[0])\n",
    "# Draw the landmark distribution after the update on the right\n",
    "draw_landmarks_distribution(x_next_kalman[3:],P_next_kalman[3:, 3:], ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Hint:}$ When your implementation is correct, the landmark distribution should shrink and focus on the position of the ground truth landmarks.\n",
    "You can check the correctness of your implementation by changing some parameters such as the robot state ${\\bf x}_{t-1}$, the displacement vector ${\\bf u}_t$ and the value of the validation gate $g$. If the landmarks distribution does not get updated correctly, try to check your measurement Jacobian $\\hat{\\bf H}_x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
